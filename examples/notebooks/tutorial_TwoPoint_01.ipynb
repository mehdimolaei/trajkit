{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-point microrheology (example)\n",
    "\n",
    "Load a CSV of tracer trajectories and compute two-point displacement correlations + derived MSDs using `trajkit.flow.two_point`.\n",
    "\n",
    "This mirrors the classic Crocker/Mason MATLAB workflow (`twopoint.m` → `msdd` → `calc_G`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Download a prepared Parquet bundle from Hugging Face and load it into a TrajectorySet (fastest path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trajkit.flow.two_point import (\n",
    "    compute_two_point_correlation,\n",
    "    distinct_msd_from_two_point,\n",
    "    compute_shear_modulus_from_msd,\n",
    ")\n",
    "from trajkit.traj.core import TrajectorySet\n",
    "\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from trajkit import load_trajectory_set\n",
    "\n",
    "\n",
    "subpath = \"data/parquet/experiment_001_2017-08-16/exp001_t027m_r01um_2017-08-16\"\n",
    "\n",
    "local_root = snapshot_download(\n",
    "    repo_id=\"m-aban/air-water\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=[f\"{subpath}/*\"],\n",
    "    local_dir=\"hf_cache\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "folder = Path(local_root) / subpath\n",
    "ts = load_trajectory_set(folder)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Compute two-point displacement correlations using log-spaced lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute two-point correlations\n",
    "tau = np.ceil(np.logspace(0,2,10)) # lag time\n",
    "corr = compute_two_point_correlation(\n",
    "    ts,\n",
    "    track_id_col=\"id\",\n",
    "    time_col=\"t\",\n",
    "    position_cols=(\"x\", \"y\"),\n",
    "    dt_values=tau,      # auto log-spaced lags\n",
    "    max_dt=100,          # max lag in frames if dt_values=None\n",
    "    r_min=10,\n",
    "    r_max=500,\n",
    "    n_r_bins=20,\n",
    "    clip_to_shared_frames=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Persist the correlation to NPZ for reuse later; reload to skip recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajkit.flow import compute_two_point_correlation, save_two_point_correlation, load_two_point_correlation\n",
    "\n",
    "# corr = compute_two_point_correlation(ts, max_dt=50, r_min=0.5, r_max=20.0)\n",
    "save_two_point_correlation(corr, \"results/two_point_corr.npz\")\n",
    "\n",
    "# Later / elsewhere\n",
    "corr_loaded = load_two_point_correlation(\"results/two_point_corr.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajkit.flow import compute_two_point_correlation, save_two_point_correlation, load_two_point_correlation\n",
    "\n",
    "save_two_point_correlation(corr, \"results/two_point_corr.npz\")\n",
    "\n",
    "# Later / elsewhere\n",
    "# corr_loaded = load_two_point_correlation(\"results/two_point_corr.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Quick look: longitudinal correlation vs separation for one representative lag (log-log)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(corr.r, corr.longitudinal[1,:])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Convert the two-point correlation into MSD (longitudinal/transverse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert two-point correlations to one-point-like MSDs (analogous to msdd.m)\n",
    "msd_from_2p = distinct_msd_from_two_point(\n",
    "    corr,\n",
    "    r_min=10,\n",
    "    r_max=500,\n",
    "    probe_radius=1.0,   # microns\n",
    "    use_linear_fit=False,\n",
    ")\n",
    "msd_from_2p.msd_longitudinal[:5], msd_from_2p.msd_transverse[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_from_2p.msd_longitudinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Derive viscoelastic moduli from the MSD (Mason-Weitz style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute viscoelastic moduli from MSD (analogous to calc_G.m / Mason-Weitz)\n",
    "moduli = compute_shear_modulus_from_msd(\n",
    "    tau=msd_from_2p.dt,\n",
    "    msd=msd_from_2p.msd_transverse,  # choose L or T\n",
    "    probe_radius_microns=1.0,\n",
    "    dim=2,\n",
    "    temperature_K=298.0,\n",
    "    clip=0.03,\n",
    "    smoothing_window=7,\n",
    "    polyorder=2,\n",
    ")\n",
    "moduli.omega[:5], moduli.Gp[:5], moduli.Gpp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Optional: alternative data access (raw CSV / Parquet pieces) if you need to rebuild trajectories manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "path = hf_hub_download(\n",
    "    repo_id=\"m-aban/air-water\",\n",
    "    filename=\"data/csv/experiment_001_2017-08-16/exp001_t000m_r01um_2017-08-16.csv.gz\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "pathTraj = hf_hub_download(\n",
    "    repo_id=\"m-aban/air-water\",\n",
    "    filename=\"data/parquet/experiment_001_2017-08-16/exp001_t000m_r01um_2017-08-16/tracks_index.parquet\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "ts = pd.read_parquet(pathTraj)\n",
    "ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajkit import TrajectorySet\n",
    "df = pd.read_parquet(\"tracks.parquet\")\n",
    "ts = TrajectorySet.from_dataframe(df, dataset_id=\"air-water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "from trajkit import load_trajectory_set\n",
    "\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "subpath = \"data/parquet/experiment_001_2017-08-16/exp001_t027m_r01um_2017-08-16\"\n",
    "\n",
    "local_root = snapshot_download(\n",
    "    repo_id=\"m-aban/air-water\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=[f\"{subpath}/*\"],\n",
    "    local_dir=\"hf_cache\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "folder = Path(local_root) / subpath\n",
    "ts = load_trajectory_set(folder)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(local_root) / \"data/parquet/experiment_001_2017-08-16/exp001_t027m_r01um_2017-08-16\"\n",
    "ts = load_trajectory_set(folder)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "path = hf_hub_download(\n",
    "    repo_id=\"m-aban/air-water\",\n",
    "    filename=\"data/csv/experiment_001_2017-08-16/exp001_t000m_r01um_2017-08-16.csv.gz\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess, json\n",
    "print(sys.executable)\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"huggingface_hub>=0.24\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"show\", \"huggingface_hub\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
