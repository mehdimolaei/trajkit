{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CDV position snapshot (single frame)\n",
    "\n",
    "Build a `TrajectorySet` from CSV (t column treated as frame index), grab x/y coordinates at a specific time `t0` across all trajectories, assemble a displacement table over `delta_t` frames, and visualize a scatter of positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trajkit import Trajectory, TrajectorySet\n",
    "\n",
    "csv_path = \"/Users/mehdi/particleTraj/res_xyti_time11.csv\"  # update to your path\n",
    "t0 = 0.0        # time of interest (frames, since we treat t as frame index)\n",
    "time_tol = 1e-3 # tolerance (frames) when matching t0 inside each trajectory\n",
    "\n",
    "\n",
    "def normalize_track_id(raw_id):\n",
    "    \"\"\"Convert numeric ids like 1.0 -> \"1\" while keeping other labels intact.\"\"\"\n",
    "    try:\n",
    "        as_int = int(raw_id)\n",
    "        if float(raw_id) == as_int:\n",
    "            return str(as_int)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(raw_id)\n",
    "\n",
    "\n",
    "# Build TrajectorySet\n",
    "df = pd.read_csv(csv_path).sort_values([\"id\", \"t\"])\n",
    "ts = TrajectorySet(\n",
    "    dataset_id=\"airwater_1um\",\n",
    "    units={\"t\": \"frame\", \"x\": \"pixel\"},\n",
    "    meta={\"source\": str(csv_path)},\n",
    ")\n",
    "\n",
    "for tid, df_tid in df.groupby(\"id\", sort=False):\n",
    "    df_tid = df_tid.sort_values(\"t\").reset_index(drop=True)\n",
    "    coords = df_tid[[\"x\", \"y\"]].to_numpy(dtype=float)\n",
    "    frames = df_tid[\"t\"].to_numpy(dtype=float)  # treat 't' column as frame index\n",
    "    ts.add(\n",
    "        Trajectory(\n",
    "            track_id=normalize_track_id(tid),\n",
    "            x=coords,\n",
    "            frame=frames,\n",
    "            frame_rate_hz=1.0,  # so time_seconds() == frame index\n",
    "        )\n",
    "    )\n",
    "\n",
    "ts.summary_table().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build displacement table across all trajectories (delta_t in frames)\n",
    "delta_t_frames = 1.0\n",
    "disp_rows = []\n",
    "for tid, tr in ts.trajectories.items():\n",
    "    t = tr.time_seconds()\n",
    "    frames = tr.frame if tr.frame is not None else np.arange(len(t), dtype=int)\n",
    "    targets = t + delta_t_frames\n",
    "    idx = np.searchsorted(t, targets, side=\"left\")\n",
    "    for i, j in enumerate(idx):\n",
    "        if j >= len(t):\n",
    "            continue\n",
    "        if abs(t[j] - targets[i]) > time_tol:\n",
    "            continue\n",
    "        dx = tr.x[j] - tr.x[i]\n",
    "        row = {\n",
    "            \"track_id\": tid,\n",
    "            \"t\": float(t[i]),\n",
    "            \"frame\": int(frames[i]) if frames is not None else i,\n",
    "        }\n",
    "        for k in range(tr.D):\n",
    "            row[f\"x{k}\"] = float(tr.x[i, k])\n",
    "            row[f\"dx{k}\"] = float(dx[k])\n",
    "        disp_rows.append(row)\n",
    "\n",
    "disp_df = pd.DataFrame(disp_rows)\n",
    "print(f\"Displacement rows: {len(disp_df)} (delta_t={delta_t_frames} frames)\")\n",
    "disp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build correlation batch using displacement table as both source and tracer\n",
    "from trajkit.cdv import correlation_batch, distance_threshold_pair_filter\n",
    "\n",
    "disp_sub = disp_df[disp_df[\"frame\"] < 3]\n",
    "position_cols = [c for c in disp_sub.columns if c.startswith(\"x\") and not c.startswith(\"dx\")]\n",
    "motion_cols = [c for c in disp_sub.columns if c.startswith(\"dx\")]\n",
    "max_pair_distance = 500  # drop pairs separated by more than this distance\n",
    "\n",
    "corr_batch , ensemble = correlation_batch(\n",
    "    disp_sub,\n",
    "    disp_sub,\n",
    "    source_frame_col=\"frame\",\n",
    "    tracer_frame_col=\"frame\",\n",
    "    source_position_cols=position_cols,\n",
    "    tracer_position_cols=position_cols,\n",
    "    source_motion_cols=motion_cols,\n",
    "    tracer_motion_cols=motion_cols,\n",
    "    pair_filter=distance_threshold_pair_filter(max_pair_distance),\n",
    ")\n",
    "print(f\"Correlation pairs: {corr_batch.n_pairs}\")\n",
    "corr_batch.meta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_r_df = batch_r.to_dataframe()\n",
    "batch_r_df.head()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(batch_r_df[\"rel_pos_0\"], batch_r_df[\"rel_pos_1\"], s=1)\n",
    "plt.quiver(batch_r_df[\"rel_pos_0\"], batch_r_df[\"rel_pos_1\"], batch_r_df[\"tracer_motion_0\"], batch_r_df[\"tracer_motion_1\"], scale=70, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid for correlation ensemble using meshgrid centers and accumulate by frame\n",
    "import numpy as np\n",
    "from trajkit.cdv import correlation_batch, CorrelationEnsembleAccumulator\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(-300.0, 300.0, 50)\n",
    "y = np.linspace(-300.0, 300.0, 50)\n",
    "X, Y = np.meshgrid(x, y, indexing='xy')\n",
    "grid_centers = np.stack([X.ravel(), Y.ravel()], axis=1)\n",
    "\n",
    "ensemble = CorrelationEnsembleAccumulator(\n",
    "    grid_centers,\n",
    "    kernel=50.0,  # hard cutoff radius in rel_pos space\n",
    "    value_fn=lambda rel, tracer, source, meta_row: tracer,\n",
    "    weight_fn=lambda rel, tracer, source, meta_row: np.linalg.norm(source),\n",
    ")\n",
    "\n",
    "# Add two batches (frames 1 and 2)\n",
    "disp_f12 = disp_df[disp_df['frame'].isin([1, 2])]\n",
    "batch_f1, _ = correlation_batch(\n",
    "    disp_f12[disp_f12['frame'] == 1],\n",
    "    disp_f12[disp_f12['frame'] == 1],\n",
    "    source_frame_col='frame', tracer_frame_col='frame',\n",
    "    source_position_cols=position_cols, tracer_position_cols=position_cols,\n",
    "    source_motion_cols=motion_cols, tracer_motion_cols=motion_cols,\n",
    ")\n",
    "batch_f2, _ = correlation_batch(\n",
    "    disp_f12[disp_f12['frame'] == 2],\n",
    "    disp_f12[disp_f12['frame'] == 2],\n",
    "    source_frame_col='frame', tracer_frame_col='frame',\n",
    "    source_position_cols=position_cols, tracer_position_cols=position_cols,\n",
    "    source_motion_cols=motion_cols, tracer_motion_cols=motion_cols,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = CorrelationEnsembleAccumulator(\n",
    "    grid_centers,\n",
    "    kernel=50.0,  # hard cutoff radius in rel_pos space\n",
    "    value_fn=lambda rel, tracer, source, meta_row: tracer,\n",
    "    weight_fn=lambda rel, tracer, source, meta_row: np.linalg.norm(source),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.add(batch_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.add(batch_f1)\n",
    "ensemble.add(batch_f2)\n",
    "mean, sum_w, counts = ensemble.finalize()\n",
    "mean.shape, float(sum_w.sum()), float(counts.sum() if counts is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trajkit.cdv import correlation_batch, CorrelationEnsembleAccumulator, distance_threshold_pair_filter\n",
    "\n",
    "position_cols = [c for c in disp_df.columns if c.startswith(\"x\") and not c.startswith(\"dx\")]\n",
    "motion_cols = [c for c in disp_df.columns if c.startswith(\"dx\")]\n",
    "max_pair_distance = 600  # drop pairs separated by more than this distance\n",
    "\n",
    "\n",
    "x = np.linspace(-400.0, 400.0, 100)\n",
    "y = np.linspace(-400.0, 400.0, 100)\n",
    "X, Y = np.meshgrid(x, y, indexing='xy')\n",
    "grid_centers = np.stack([X.ravel(), Y.ravel()], axis=1)\n",
    "\n",
    "ensemble = CorrelationEnsembleAccumulator(\n",
    "    grid_centers,\n",
    "    kernel=30.0,  # hard cutoff radius in rel_pos space\n",
    "    value_fn=lambda rel, tracer, source, meta_row: tracer,\n",
    "    weight_fn=lambda rel, tracer, source, meta_row: np.linalg.norm(source),\n",
    ")\n",
    "for i in range(1000):\n",
    "    disp_temp = disp_df[disp_df['frame'] == i]\n",
    "    batch, _ = correlation_batch(\n",
    "        disp_temp,\n",
    "        disp_temp,\n",
    "        source_frame_col='frame', tracer_frame_col='frame',\n",
    "        source_position_cols=position_cols, tracer_position_cols=position_cols,\n",
    "        source_motion_cols=motion_cols, tracer_motion_cols=motion_cols,\n",
    "        pair_filter=distance_threshold_pair_filter(max_pair_distance),\n",
    "    )\n",
    "    batch_r = batch.rotate_to_source_x()\n",
    "    ensemble.add(batch_r)\n",
    "    print(f\"{i}\")\n",
    "mean, sum_w, counts = ensemble.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = ensemble.sum_v          # shape: (M, 2) for x/y components\n",
    "weights = ensemble.sum_w     # shape: (M,)\n",
    "W = weights.reshape(Y.shape)\n",
    "U = ff[:, 0].reshape(Y.shape)/W\n",
    "V = ff[:, 1].reshape(Y.shape)/W\n",
    "\n",
    "mag = np.log10(np.sqrt(U**2 + V**2))\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Contour of magnitude\n",
    "cs = plt.contourf(X, Y, mag, levels=20, cmap=\"viridis\")\n",
    "plt.colorbar(cs, label=\"||ff||\")\n",
    "\n",
    "# Streamlines (linewidth scales with magnitude)\n",
    "plt.streamplot(\n",
    "    X, Y, U, V,\n",
    "    color=\"k\",\n",
    "    density=1.2,\n",
    "    arrowsize=1.2,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Correlation ensemble field\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trajkit.cdv import correlation_batch, CorrelationEnsembleAccumulator, distance_threshold_pair_filter\n",
    "from time import perf_counter\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "position_cols = [c for c in disp_df.columns if c.startswith(\"x\") and not c.startswith(\"dx\")]\n",
    "motion_cols = [c for c in disp_df.columns if c.startswith(\"dx\")]\n",
    "max_pair_distance = 600  # drop pairs separated by more than this distance\n",
    "\n",
    "\n",
    "x = np.linspace(-400.0, 400.0, 100)\n",
    "y = np.linspace(-400.0, 400.0, 100)\n",
    "X, Y = np.meshgrid(x, y, indexing='xy')\n",
    "grid_centers = np.stack([X.ravel(), Y.ravel()], axis=1)\n",
    "\n",
    "ensemble2 = CorrelationEnsembleAccumulator(\n",
    "    grid_centers,\n",
    "    kernel=30.0,  # hard cutoff radius in rel_pos space\n",
    "    value_fn=lambda rel, tracer, source, meta_row: tracer,\n",
    "    weight_fn=lambda rel, tracer, source, meta_row: np.linalg.norm(source),\n",
    ")\n",
    "times = []\n",
    "for i in range(200):\n",
    "    t0 = perf_counter()\n",
    "    disp_temp = disp_df[disp_df['frame'] == i]\n",
    "    batch, _ = correlation_batch(\n",
    "        disp_temp,\n",
    "        disp_temp,\n",
    "        source_frame_col='frame', tracer_frame_col='frame',\n",
    "        source_position_cols=position_cols, tracer_position_cols=position_cols,\n",
    "        source_motion_cols=motion_cols, tracer_motion_cols=motion_cols,\n",
    "        pair_filter=distance_threshold_pair_filter(max_pair_distance),\n",
    "    )\n",
    "    batch_r = batch.rotate_to_source_x()\n",
    "    ensemble2.add(batch_r)\n",
    "    t1 = perf_counter()\n",
    "    duration = t1 - t0\n",
    "    times.append(duration)\n",
    "\n",
    "    # update plot each iteration\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(np.arange(1, len(times) + 1), times, '-o', ms=3)\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"time (s)\")\n",
    "    plt.title(\"Per-iteration time\")\n",
    "    plt.grid(True)\n",
    "    display(plt.gcf())\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"{i}  iter_time={duration:.4f}s\")\n",
    "mean, sum_w, counts = ensemble.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ff = ensemble.sum_v          # shape: (M, 2) for x/y components\n",
    "weights = ensemble.sum_w     # shape: (M,)\n",
    "\n",
    "# Reshape to grid\n",
    "U = ff[:, 0].reshape(Y.shape)\n",
    "\n",
    "\n",
    "# Mask cells with no weight\n",
    "mask = W <= 0\n",
    "U_masked = np.ma.array(U, mask=mask)\n",
    "V_masked = np.ma.array(V, mask=mask)\n",
    "mag_masked = np.ma.array(mag, mask=mask)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Contour of magnitude\n",
    "cs = plt.contourf(X, Y, mag_masked, levels=20, cmap=\"viridis\")\n",
    "plt.colorbar(cs, label=\"||ff||\")\n",
    "\n",
    "# Streamlines (linewidth scales with magnitude)\n",
    "plt.streamplot(\n",
    "    X, Y, U_masked, V_masked,\n",
    "    color=\"k\",\n",
    "    density=1.2,\n",
    "    linewidth=1 + 2 * (mag_masked / (mag_masked.max() + 1e-9)),\n",
    "    arrowsize=1.2,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Correlation ensemble field\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trajkit.cdv import correlation_batch, CorrelationEnsembleAccumulator, distance_threshold_pair_filter\n",
    "from time import perf_counter\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "position_cols = [c for c in disp_df.columns if c.startswith(\"x\") and not c.startswith(\"dx\")]\n",
    "motion_cols = [c for c in disp_df.columns if c.startswith(\"dx\")]\n",
    "max_pair_distance = 600  # drop pairs separated by more than this distance\n",
    "\n",
    "\n",
    "x = np.linspace(-400.0, 400.0, 100)\n",
    "y = np.linspace(-400.0, 400.0, 100)\n",
    "X, Y = np.meshgrid(x, y, indexing='xy')\n",
    "grid_centers = np.stack([X.ravel(), Y.ravel()], axis=1)\n",
    "\n",
    "ensemble2 = CorrelationEnsembleAccumulator(\n",
    "    grid_centers,\n",
    "    kernel=30.0,  # hard cutoff radius in rel_pos space\n",
    "    value_fn=lambda rel, tracer, source, meta_row: tracer,\n",
    "    weight_fn=lambda rel, tracer, source, meta_row: np.linalg.norm(source),\n",
    ")\n",
    "times = []\n",
    "\n",
    "i = 1\n",
    "t0 = perf_counter()\n",
    "disp_temp = disp_df[disp_df['frame'] == i]\n",
    "batch, _ = correlation_batch(\n",
    "    disp_temp,\n",
    "    disp_temp,\n",
    "    source_frame_col='frame', tracer_frame_col='frame',\n",
    "    source_position_cols=position_cols, tracer_position_cols=position_cols,\n",
    "    source_motion_cols=motion_cols, tracer_motion_cols=motion_cols,\n",
    "    pair_filter=distance_threshold_pair_filter(max_pair_distance),\n",
    ")\n",
    "batch_r = batch.rotate_to_source_x()\n",
    "ensemble2.add(batch_r)\n",
    "t1 = perf_counter()\n",
    "duration = t1 - t0\n",
    "times.append(duration)\n",
    "\n",
    "# update plot each iteration\n",
    "clear_output(wait=True)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(np.arange(1, len(times) + 1), times, '-o', ms=3)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"time (s)\")\n",
    "plt.title(\"Per-iteration time\")\n",
    "plt.grid(True)\n",
    "display(plt.gcf())\n",
    "plt.close()\n",
    "\n",
    "print(f\"{i}  iter_time={duration:.4f}s\")\n",
    "# mean, sum_w, counts = ensemble.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
